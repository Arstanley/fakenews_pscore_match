{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = {'ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 432, 16817, 5323)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "politifact_real = pd.read_csv('./FakeNewsNet-master/dataset/politifact_real.csv')\n",
    "politifact_fake = pd.read_csv('./FakeNewsNet-master/dataset/politifact_fake.csv')\n",
    "gossipcop_real = pd.read_csv('./FakeNewsNet-master/dataset/gossipcop_real.csv')\n",
    "gossipcop_fake = pd.read_csv('./FakeNewsNet-master/dataset/gossipcop_fake.csv')\n",
    "len(politifact_real), len(politifact_fake), len(gossipcop_real), len(gossipcop_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact_real = politifact_real.sample(432)\n",
    "gossipcop_real = gossipcop_real.sample(5323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact_real['label'] = 1\n",
    "politifact_fake['label'] = 0\n",
    "gossipcop_real['label'] = 1\n",
    "gossipcop_fake['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact = pd.concat((politifact_fake, politifact_real), axis=0)\n",
    "gossipcop = pd.concat((gossipcop_real, gossipcop_fake), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(864, 10646)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(politifact), len(gossipcop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact = politifact[['title', 'label']]\n",
    "gossipcop = gossipcop[['title', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of the stop words \n",
    "def clean_stopwords(sentences):\n",
    "    \"\"\"\n",
    "    input: array of sentences\n",
    "    \"\"\"\n",
    "    word_list = re.findall(r'\\w+', sentences)\n",
    "    ans = ''\n",
    "    for word in word_list:\n",
    "        if word in stop_words:\n",
    "            pass\n",
    "        ans += word + ' '\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact['title'] = politifact['title'].map(lambda x: clean_stopwords(x))\n",
    "gossipcop['title'] = gossipcop['title'].map(lambda x: clean_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    432\n",
      "0    432\n",
      "Name: label, dtype: int64\n",
      "1    5323\n",
      "0    5323\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balancing the data\n",
    "print(politifact['label'].value_counts())\n",
    "print(gossipcop['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the text data to binary encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_processing(df):\n",
    "    \"\"\"\n",
    "    input: dataframe with label\n",
    "    \"\"\"\n",
    "    X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=100, lower=False)\n",
    "    \n",
    "    tokenizer.fit_on_texts(X_train['title'])\n",
    "    \n",
    "    X_train = tokenizer.texts_to_sequences(X_train['title'])\n",
    "    \n",
    "    X_test = tokenizer.texts_to_sequences(X_test['title'])\n",
    "  \n",
    "    vocab_size = len(tokenizer.word_index)+1\n",
    "    \n",
    "    X_train = pad_sequences(X_train, padding='post', maxlen=300) \n",
    "    \n",
    "    X_test = pad_sequences(X_test, padding='post', maxlen=300) \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_processing(politifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clf, X):\n",
    "    X_train, X_test, y_train, y_test = train_test_processing(X)\n",
    "    # clf.fit(X_train, y_train)\n",
    "    train_predict = clf.predict(X_train)\n",
    "    test_predict = clf.predict(X_test)\n",
    "    f1_score_train = f1_score(train_predict, y_train)\n",
    "    f1_score_test = f1_score(test_predict, y_test)\n",
    "    \n",
    "    print(f'Training F1: {f1_score_train}')\n",
    "    print(f'Testing F1: {f1_score_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(C=1.0, random_state=42)\n",
    "forest_clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1: 0.9319526627218936\n",
      "Testing F1: 0.6608695652173914\n"
     ]
    }
   ],
   "source": [
    "evaluate(forest_clf, politifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1: 0.468807994289793\n",
      "Testing F1: 0.47578589634664403\n"
     ]
    }
   ],
   "source": [
    "evaluate(forest_clf, gossipcop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity Score Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Calculate Propensity Score\n",
    "\n",
    "For every word, we need to build a logistic regression with other words features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 57, 44, ...,  0,  0,  0],\n",
       "       [61, 45, 14, ...,  0,  0,  0],\n",
       "       [ 6,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 6, 52, 20, ...,  0,  0,  0],\n",
       "       [ 4,  9,  3, ...,  0,  0,  0],\n",
       "       [ 9,  8,  0, ...,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
